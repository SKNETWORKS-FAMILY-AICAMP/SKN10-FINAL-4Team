import sys
import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from scipy.spatial.distance import cosine
matplotlib.rc('font', family='AppleGothic')
plt.rcParams['axes.unicode_minus'] = False
from resemblyzer import VoiceEncoder, preprocess_wav
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from scipy.spatial import ConvexHull
import librosa.display
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
from mpl_toolkits.mplot3d import art3d
from scipy import stats
import pandas as pd
from itertools import combinations

# Directories to analyze
directories = {
    'itsub_autogenerated': 'itsub_autogenerated',
    'itsub_benchmark': 'itsub_benchmark'
}

# Color and marker mapping
centroid_markers = {
    'itsub_autogenerated': 'D',
    'itsub_benchmark': 's'
}
centroid_colors = {
    'itsub_autogenerated': 'green',
    'itsub_benchmark': 'blue'
}
centroid_labels = {
    'itsub_autogenerated': 'itsub_autogenerated centroid',
    'itsub_benchmark': 'itsub_benchmark centroid'
}

# Load benchmark file
benchmark_path = 'benchmark/processed_audio.mp3'
if not os.path.exists(benchmark_path):
    print("Error: processed_audio.mp3 not found in benchmark directory")
    sys.exit(1)

encoder = VoiceEncoder()
benchmark_wav, benchmark_sr = librosa.load(benchmark_path, sr=None)
if benchmark_sr != 16000:
    benchmark_wav = librosa.resample(benchmark_wav, orig_sr=benchmark_sr, target_sr=16000)
    benchmark_sr = 16000
benchmark_wav = preprocess_wav(benchmark_wav, source_sr=benchmark_sr)
benchmark_embedding = encoder.embed_utterance(benchmark_wav)

# Process files from each directory
all_files = []
all_embeddings = []
all_labels = []
for dir_name, dir_path in directories.items():
    files = [f for f in os.listdir(dir_path) if f.endswith('.mp3')]
    files.sort()
    for fname in files:
        file_path = os.path.join(dir_path, fname)
        wav, sr = librosa.load(file_path, sr=None)
        if sr != 16000:
            wav = librosa.resample(wav, orig_sr=sr, target_sr=16000)
            sr = 16000
        wav = preprocess_wav(wav, source_sr=sr)
        embedding = encoder.embed_utterance(wav)
        all_files.append(file_path)
        all_embeddings.append(embedding)
        all_labels.append(f"{dir_name}/{os.path.splitext(fname)[0]}")

embeddings = np.array(all_embeddings)
all_embeddings_with_benchmark = np.vstack([benchmark_embedding, embeddings])

# Calculate cosine similarities
def cosine_similarity(a, b):
    return 1 - cosine(a, b)

# Calculate similarities between benchmark and all other embeddings
benchmark_similarities = [cosine_similarity(benchmark_embedding, emb) for emb in embeddings]

# Calculate similarities between all pairs
similarity_matrix = np.zeros((len(embeddings), len(embeddings)))
for i in range(len(embeddings)):
    for j in range(len(embeddings)):
        similarity_matrix[i, j] = cosine_similarity(embeddings[i], embeddings[j])

# PCA
pca = PCA(n_components=2)
reduced_pca = pca.fit_transform(all_embeddings_with_benchmark)

# t-SNE
tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_embeddings_with_benchmark)-1))
reduced_tsne = tsne.fit_transform(all_embeddings_with_benchmark)

# Create first figure for PCA and t-SNE
fig1 = plt.figure(figsize=(20, 8))
gs1 = fig1.add_gridspec(1, 2)

# --- PCA: highlight centroid-to-benchmark distances ---
ax1 = fig1.add_subplot(gs1[0, 0])
ax1.scatter(reduced_pca[0, 0], reduced_pca[0, 1],
           c='gold', label='benchmark', s=350, edgecolor='black', marker='*', zorder=10, linewidth=2)
ax1.add_patch(plt.Circle((reduced_pca[0, 0], reduced_pca[0, 1]), 0.03, color='gold', alpha=0.2, zorder=1))

# Store distances for summary statistics
distances = {}
for dir_name in directories.keys():
    mask = [label.startswith(dir_name) for label in all_labels]
    indices = np.where(mask)[0] + 1
    group_points = reduced_pca[indices]
    ax1.scatter(group_points[:, 0], group_points[:, 1],
               c=centroid_colors[dir_name], label=dir_name, s=60, edgecolor='k', alpha=0.7)
    centroid = group_points.mean(axis=0)
    ax1.scatter(*centroid, c=centroid_colors[dir_name], marker=centroid_markers[dir_name],
               s=220, edgecolor='black', label=centroid_labels[dir_name], zorder=5)
    ax1.plot([reduced_pca[0, 0], centroid[0]], [reduced_pca[0, 1], centroid[1]],
            c=centroid_colors[dir_name], linestyle='--', lw=3)
    dist = np.linalg.norm(centroid - reduced_pca[0])
    distances[dir_name] = dist
    ax1.text((reduced_pca[0, 0]+centroid[0])/2, (reduced_pca[0, 1]+centroid[1])/2,
            f'{dir_name} dist={dist:.3f}', color=centroid_colors[dir_name], fontsize=13, weight='bold')

ax1.set_title('PCA: Centroid-to-Benchmark Distance')
ax1.set_xlabel('PC1')
ax1.set_ylabel('PC2')
ax1.legend(fontsize=12)
ax1.grid(True)

# --- t-SNE: highlight group area (convex hull) ---
ax2 = fig1.add_subplot(gs1[0, 1])
ax2.scatter(reduced_tsne[0, 0], reduced_tsne[0, 1],
           c='gold', label='benchmark', s=350, edgecolor='black', marker='*', zorder=10, linewidth=2)
ax2.add_patch(plt.Circle((reduced_tsne[0, 0], reduced_tsne[0, 1]), 0.03, color='gold', alpha=0.2, zorder=1))

def plot_convex_hull(ax, points, color, alpha=0.18, label=None):
    if len(points) < 3:
        return None
    hull = ConvexHull(points)
    hull_points = points[hull.vertices]
    poly = plt.Polygon(hull_points, color=color, alpha=alpha, label=label)
    ax.add_patch(poly)
    return hull.area

# Store convex hull areas
hull_areas = {}
for dir_name in directories.keys():
    mask = [label.startswith(dir_name) for label in all_labels]
    indices = np.where(mask)[0] + 1
    group_points = reduced_tsne[indices]
    # Remove outlier for elevenlabs
    if dir_name == 'final_processed' and len(group_points) > 3:
        centroid = group_points.mean(axis=0)
        dists = np.linalg.norm(group_points - centroid, axis=1)
        outlier_idx = np.argmax(dists)
        group_points = np.delete(group_points, outlier_idx, axis=0)
    area = plot_convex_hull(ax2, group_points, centroid_colors[dir_name], alpha=0.18, label=f'{dir_name} area')
    ax2.scatter(group_points[:, 0], group_points[:, 1],
               c=centroid_colors[dir_name], label=dir_name, s=60, edgecolor='k', alpha=0.7)
    if area is not None:
        hull_areas[dir_name] = area
        centroid = group_points.mean(axis=0)
        ax2.text(centroid[0], centroid[1], f'area={area:.1f}', color=centroid_colors[dir_name], fontsize=13, weight='bold', bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))

ax2.set_title('t-SNE: Group Area (Convex Hull)')
ax2.set_xlabel('t-SNE 1')
ax2.set_ylabel('t-SNE 2')
ax2.legend(fontsize=12)
ax2.grid(True)

plt.tight_layout()
plt.savefig('audio_similarity_spatial.png', dpi=300, bbox_inches='tight')
plt.close()

# Create second figure for cosine similarity statistics with hard-coded values
fig2 = plt.figure(figsize=(10, 6))
ax3 = fig2.add_subplot(111)
x = np.arange(2)  # Two groups: supertones and elevenlabs
width = 0.6

# Calculate cosine similarity statistics for each group (to benchmark)
group_order = ['itsub_autogenerated', 'itsub_benchmark']
actual_stats = {}
for dir_name in group_order:
    mask = [label.startswith(dir_name) for label in all_labels]
    indices = np.where(mask)[0]
    group_embeddings = embeddings[indices]
    group_similarities = [cosine_similarity(benchmark_embedding, emb) for emb in group_embeddings]
    actual_stats[dir_name] = {
        'mean': np.mean(group_similarities),
        'std': np.std(group_similarities),
        'min': np.min(group_similarities),
        'max': np.max(group_similarities)
    }

# Plot bars with error bars
means = [actual_stats[g]['mean'] for g in group_order]
stds = [actual_stats[g]['std'] for g in group_order]
mins = [actual_stats[g]['min'] for g in group_order]
maxs = [actual_stats[g]['max'] for g in group_order]

bars = ax3.bar(np.arange(len(group_order)), means, width, yerr=stds, capsize=5, 
               color=[centroid_colors[g] for g in group_order],
               alpha=0.7, label='Mean Â± Std')

# Add min-max range as error bars
for i, (min_val, max_val) in enumerate(zip(mins, maxs)):
    ax3.errorbar(i, means[i], yerr=[[means[i] - min_val], [max_val - means[i]]], 
                fmt='none', color='black', capsize=5, capthick=1, elinewidth=1)

# Add value labels
for i, dir_name in enumerate(group_order):
    # Mean value
    ax3.text(i, means[i], f'{means[i]:.3f}', 
            ha='center', va='bottom', fontsize=10)
    # Min value
    ax3.text(i, mins[i], f'{mins[i]:.3f}', 
            ha='center', va='top', fontsize=8, color='gray')
    # Max value
    ax3.text(i, maxs[i], f'{maxs[i]:.3f}', 
            ha='center', va='bottom', fontsize=8, color='gray')

ax3.set_ylabel('Cosine Similarity')
ax3.set_title('Cosine Similarity Statistics by Group')
ax3.set_xticks(np.arange(len(group_order)))
ax3.set_xticklabels(['itsub_autogenerated', 'itsub_benchmark'])
ax3.grid(True, axis='y')

# Add legend
ax3.errorbar([], [], yerr=[], fmt='none', color='black', capsize=5, capthick=1, elinewidth=1, label='Min-Max Range')
ax3.errorbar([], [], yerr=[], fmt='none', color='gray', capsize=5, capthick=1, elinewidth=1, label='Std Dev')
ax3.legend()

plt.tight_layout()
plt.savefig('audio_similarity_stats.png', dpi=300, bbox_inches='tight')
plt.close()

# Print summary statistics
print("\n=== Cosine Similarity Statistics (to Benchmark) ===")
for dir_name in group_order:
    print(f"\n{dir_name}:")
    for stat_name in ['mean', 'std', 'min', 'max']:
        print(f"{stat_name.capitalize()}: {actual_stats[dir_name][stat_name]:.3f}")

# --- MFCC Feature Extraction and Visualization ---
print("\nExtracting MFCCs and visualizing group means with tweaked parameters...")

def pre_emphasis(signal, coeff=0.97):
    return np.append(signal[0], signal[1:] - coeff * signal[:-1])

n_mfcc = 8  # Use only the first 8 MFCCs
hop_length = 256
n_fft = 1024

# Preprocess and extract MFCC for benchmark
benchmark_wav_norm = benchmark_wav / np.max(np.abs(benchmark_wav))
benchmark_wav_preemph = pre_emphasis(benchmark_wav_norm)
mfccs_benchmark = librosa.feature.mfcc(y=benchmark_wav_preemph, sr=benchmark_sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)

# Store MFCCs for each group
mfccs_by_group = {g: [] for g in group_order}
for dir_name, dir_path in directories.items():
    files = [f for f in os.listdir(dir_path) if f.endswith('.mp3')]
    files.sort()
    for fname in files:
        file_path = os.path.join(dir_path, fname)
        wav, sr = librosa.load(file_path, sr=None)
        if sr != 16000:
            wav = librosa.resample(wav, orig_sr=sr, target_sr=16000)
            sr = 16000
        wav = preprocess_wav(wav, source_sr=sr)
        wav_norm = wav / np.max(np.abs(wav))
        wav_preemph = pre_emphasis(wav_norm)
        mfcc = librosa.feature.mfcc(y=wav_preemph, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)
        mfccs_by_group[dir_name].append(mfcc)

# Compute mean MFCC for each group (mean over files, then mean over time axis)
mean_mfccs = {}
mean_mfcc_vectors = {}
for group in group_order:
    if len(mfccs_by_group[group]) > 0:
        # Pad/truncate to the shortest time axis for fair averaging
        min_frames = min(m.shape[1] for m in mfccs_by_group[group])
        mfccs_trimmed = [m[:, :min_frames] for m in mfccs_by_group[group]]
        mean_mfcc = np.mean(mfccs_trimmed, axis=0)
        mean_mfccs[group] = mean_mfcc
        mean_mfcc_vectors[group] = mean_mfcc.mean(axis=1)  # mean over time axis
    else:
        mean_mfccs[group] = None
        mean_mfcc_vectors[group] = None
# For benchmark, trim to min_frames of the first group
min_frames_bench = min(m.shape[1] for m in mfccs_by_group[group_order[0]])
mfccs_benchmark_trim = mfccs_benchmark[:, :min_frames_bench]
mean_mfcc_vector_benchmark = mfccs_benchmark_trim.mean(axis=1)

# 1. Bar plot of mean MFCC vector for each group and benchmark
plt.figure(figsize=(10, 5))
bar_width = 0.18
x = np.arange(n_mfcc)
bar_colors = [centroid_colors[g] for g in group_order]
for i, group in enumerate(group_order):
    if mean_mfcc_vectors[group] is not None:
        plt.bar(x + i*bar_width, mean_mfcc_vectors[group], width=bar_width, label=group.replace('_', ' ').title(), color=bar_colors[i])
plt.bar(x + len(group_order)*bar_width, mean_mfcc_vector_benchmark, width=bar_width, label='Benchmark', color='gray')
plt.xlabel('MFCC Coefficient')
plt.ylabel('Mean Value')
plt.title('Mean MFCC Vector by Group and Benchmark (Tweaked)')
plt.xticks(x + bar_width, [f'MFCC {i+1}' for i in range(n_mfcc)])
plt.legend()
plt.tight_layout()
plt.savefig('mean_mfcc_vector_barplot_tweaked.png', dpi=300, bbox_inches='tight')
plt.close()
print("Saved mean MFCC vector bar plot as mean_mfcc_vector_barplot_tweaked.png")

# Calculate and print mean absolute difference for each MFCC coefficient
print("\n=== Mean Absolute Difference from Benchmark for Each MFCC Coefficient (Tweaked) ===")
for group in group_order:
    if mean_mfcc_vectors[group] is not None:
        abs_diff = np.abs(mean_mfcc_vectors[group] - mean_mfcc_vector_benchmark)
        print(f"\n{group.replace('_', ' ').title()}:")
        for i, diff in enumerate(abs_diff):
            print(f"MFCC {i+1}: {diff:.3f}")

# 2. Bar plot of Euclidean distance to benchmark
from scipy.spatial.distance import euclidean
mfcc_distances = {}
for group in group_order:
    if mean_mfcc_vectors[group] is not None:
        mfcc_distances[group] = euclidean(mean_mfcc_vectors[group], mean_mfcc_vector_benchmark)
    else:
        mfcc_distances[group] = np.nan
plt.figure(figsize=(7, 5))
plt.bar([g.replace('_', ' ').title() for g in group_order], [mfcc_distances[g] for g in group_order], color=bar_colors)
plt.ylabel('Euclidean Distance')
plt.title('MFCC Distance to Benchmark (Mean Vector, Tweaked)')
for i, g in enumerate(group_order):
    plt.text(i, mfcc_distances[g] + 0.01, f'{mfcc_distances[g]:.2f}', ha='center', va='bottom', fontsize=12)
plt.tight_layout()
plt.savefig('mfcc_distance_to_benchmark_tweaked.png', dpi=300, bbox_inches='tight')
plt.close()
print("Saved MFCC distance to benchmark bar plot as mfcc_distance_to_benchmark_tweaked.png")

# Create 3D visualization combining PCA and t-SNE
print("\nCreating 3D visualization combining PCA and t-SNE...")
fig3d = plt.figure(figsize=(12, 8))
ax3d = fig3d.add_subplot(111, projection='3d')

# Plot benchmark point
ax3d.scatter(reduced_pca[0, 0], reduced_pca[0, 1], reduced_tsne[0, 1],
            c='gold', label='benchmark', s=350, edgecolor='black', marker='*', zorder=10, linewidth=2)

# Plot points for each group
for dir_name in directories.keys():
    mask = [label.startswith(dir_name) for label in all_labels]
    indices = np.where(mask)[0] + 1
    group_points_pca = reduced_pca[indices]
    group_points_tsne = reduced_tsne[indices]
    
    # Plot individual points
    ax3d.scatter(group_points_pca[:, 0], group_points_pca[:, 1], group_points_tsne[:, 1],
                c=centroid_colors[dir_name], label=dir_name, s=20, edgecolor='k', alpha=0.7)
    
    # Plot centroid
    centroid_pca = group_points_pca.mean(axis=0)
    centroid_tsne = group_points_tsne.mean(axis=0)
    ax3d.scatter(centroid_pca[0], centroid_pca[1], centroid_tsne[1],
                c=centroid_colors[dir_name], marker=centroid_markers[dir_name],
                s=220, edgecolor='black', label=centroid_labels[dir_name], zorder=5)
    
    # Draw line from benchmark to centroid
    ax3d.plot([reduced_pca[0, 0], centroid_pca[0]], 
             [reduced_pca[0, 1], centroid_pca[1]],
             [reduced_tsne[0, 1], centroid_tsne[1]],
             c=centroid_colors[dir_name], linestyle='--', lw=2)
    
    # Add convex hull
    if len(group_points_pca) >= 3:  # Need at least 3 points for a convex hull
        # Create points for convex hull (combining PCA and t-SNE coordinates)
        hull_points = np.column_stack((group_points_pca[:, 0], 
                                     group_points_pca[:, 1], 
                                     group_points_tsne[:, 1]))
        hull = ConvexHull(hull_points)
        
        # Plot the convex hull as a volume using Poly3DCollection
        faces = [hull_points[simplex] for simplex in hull.simplices]
        poly3d = Poly3DCollection(faces, alpha=0.05, facecolor=centroid_colors[dir_name], edgecolor=centroid_colors[dir_name])
        ax3d.add_collection3d(poly3d)

# Set labels and title
ax3d.set_xlabel('PCA 1')
ax3d.set_ylabel('PCA 2')
ax3d.set_zlabel('t-SNE 2')
ax3d.set_title('3D Visualization: PCA + t-SNE')

# Add legend
ax3d.legend(fontsize=10)

# Adjust the viewing angle for better visualization
ax3d.view_init(elev=20, azim=45)

plt.tight_layout()
plt.savefig('audio_similarity_3d_combined.png', dpi=300, bbox_inches='tight')
print("Saved 3D combined visualization as audio_similarity_3d_combined.png")
plt.show()  # Keep the interactive window open

# Statistical Analysis and Visualization
print("\nPerforming statistical analysis...")

# Create a DataFrame for statistical analysis
data = []
for dir_name in directories.keys():
    mask = [label.startswith(dir_name) for label in all_labels]
    indices = np.where(mask)[0]
    group_embeddings = embeddings[indices]
    group_similarities = [cosine_similarity(benchmark_embedding, emb) for emb in group_embeddings]
    for sim in group_similarities:
        data.append({'Group': dir_name, 'Similarity': sim})

df = pd.DataFrame(data)

# Perform ANOVA
groups = [df[df['Group'] == g]['Similarity'] for g in directories.keys()]
f_stat, p_value = stats.f_oneway(*groups)

print("\n=== Statistical Analysis Results ===")
print(f"ANOVA F-statistic: {f_stat:.4f}")
print(f"p-value: {p_value:.4e}")

# Perform pairwise t-tests with Bonferroni correction
print("\nPairwise Comparisons (Bonferroni-corrected):")
pairs = list(combinations(directories.keys(), 2))
p_values = []  # Store all p-values for correction
pair_results = []  # Store results for each pair

for pair in pairs:
    group1, group2 = pair
    t_stat, p_val = stats.ttest_ind(
        df[df['Group'] == group1]['Similarity'],
        df[df['Group'] == group2]['Similarity']
    )
    p_values.append(p_val)
    pair_results.append((group1, group2, p_val))

# Apply Bonferroni correction manually
n_tests = len(p_values)
p_adjusted = [p * n_tests for p in p_values]  # Bonferroni correction

# Print results with corrected p-values
for (group1, group2, _), p_val_corrected in zip(pair_results, p_adjusted):
    significance = "***" if p_val_corrected < 0.001 else "**" if p_val_corrected < 0.01 else "*" if p_val_corrected < 0.05 else "ns"
    print(f"{group1} vs {group2}: p-value = {p_val_corrected:.4e} {significance}")

# Create statistical visualization
plt.figure(figsize=(12, 6))

# 1. Box plot with statistical significance
plt.subplot(1, 2, 1)
sns.boxplot(data=df, x='Group', y='Similarity', palette=centroid_colors)
plt.title('Distribution of Similarities by Group')
plt.xticks(rotation=45)

# Add significance markers
y_max = df['Similarity'].max()
y_range = df['Similarity'].max() - df['Similarity'].min()
for i, ((group1, group2, _), p_val_corrected) in enumerate(zip(pair_results, p_adjusted)):
    x1 = list(directories.keys()).index(group1)
    x2 = list(directories.keys()).index(group2)
    y = y_max + (i + 1) * 0.05 * y_range
    
    # Draw significance line
    plt.plot([x1, x2], [y, y], 'k-', lw=1)
    
    # Add significance markers
    if p_val_corrected < 0.001:
        sig_text = "***"
    elif p_val_corrected < 0.01:
        sig_text = "**"
    elif p_val_corrected < 0.05:
        sig_text = "*"
    else:
        sig_text = "ns"
    
    plt.text((x1 + x2) / 2, y + 0.02 * y_range, 
             f"{sig_text}\np={p_val_corrected:.2e}",
             ha='center', va='bottom', fontsize=8)

# 2. Violin plot with individual points
plt.subplot(1, 2, 2)
sns.violinplot(data=df, x='Group', y='Similarity', palette=centroid_colors, inner='box')
sns.stripplot(data=df, x='Group', y='Similarity', color='black', alpha=0.3, size=4)
plt.title('Distribution with Individual Points')
plt.xticks(rotation=45)

# Add significance markers to violin plot as well
for i, ((group1, group2, _), p_val_corrected) in enumerate(zip(pair_results, p_adjusted)):
    x1 = list(directories.keys()).index(group1)
    x2 = list(directories.keys()).index(group2)
    y = y_max + (i + 1) * 0.05 * y_range
    
    # Draw significance line
    plt.plot([x1, x2], [y, y], 'k-', lw=1)
    
    # Add significance markers
    if p_val_corrected < 0.001:
        sig_text = "***"
    elif p_val_corrected < 0.01:
        sig_text = "**"
    elif p_val_corrected < 0.05:
        sig_text = "*"
    else:
        sig_text = "ns"
    
    plt.text((x1 + x2) / 2, y + 0.02 * y_range, 
             f"{sig_text}\np={p_val_corrected:.2e}",
             ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.savefig('statistical_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Print summary statistics
print("\n=== Summary Statistics by Group ===")
summary_stats = df.groupby('Group')['Similarity'].agg(['mean', 'std', 'min', 'max', 'count'])
print(summary_stats)

# Save statistical results to CSV
summary_stats.to_csv('statistical_results.csv')
print("\nSaved statistical results to 'statistical_results.csv'") 